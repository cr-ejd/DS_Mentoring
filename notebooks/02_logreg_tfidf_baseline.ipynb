{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9228b286",
   "metadata": {},
   "source": [
    "# Importing libraries + loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2091bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb7f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c967a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed train data...\n",
      "Train shape: (7558, 235)\n",
      "Test raw shape: (3263, 4)\n",
      "Shape: (7558, 235)\n",
      "Columns: ['id', 'target', 'clean_text', 'url_count', 'typo_count', 'hashtag_count', 'has_url', 'has_hashtag', 'has_typos', 'eda_char_count', 'eda_word_count', 'location_encoded', 'keyword_clean_accident', 'keyword_clean_aftershock', 'keyword_clean_airplane%20accident', 'keyword_clean_ambulance', 'keyword_clean_annihilated', 'keyword_clean_annihilation', 'keyword_clean_apocalypse', 'keyword_clean_armageddon', 'keyword_clean_army', 'keyword_clean_arson', 'keyword_clean_arsonist', 'keyword_clean_attack', 'keyword_clean_attacked', 'keyword_clean_avalanche', 'keyword_clean_battle', 'keyword_clean_bioterror', 'keyword_clean_bioterrorism', 'keyword_clean_blaze', 'keyword_clean_blazing', 'keyword_clean_bleeding', 'keyword_clean_blew%20up', 'keyword_clean_blight', 'keyword_clean_blizzard', 'keyword_clean_blood', 'keyword_clean_bloody', 'keyword_clean_blown%20up', 'keyword_clean_body%20bag', 'keyword_clean_body%20bagging', 'keyword_clean_body%20bags', 'keyword_clean_bomb', 'keyword_clean_bombed', 'keyword_clean_bombing', 'keyword_clean_bridge%20collapse', 'keyword_clean_buildings%20burning', 'keyword_clean_buildings%20on%20fire', 'keyword_clean_burned', 'keyword_clean_burning', 'keyword_clean_burning%20buildings', 'keyword_clean_bush%20fires', 'keyword_clean_casualties', 'keyword_clean_casualty', 'keyword_clean_catastrophe', 'keyword_clean_catastrophic', 'keyword_clean_chemical%20emergency', 'keyword_clean_cliff%20fall', 'keyword_clean_collapse', 'keyword_clean_collapsed', 'keyword_clean_collide', 'keyword_clean_collided', 'keyword_clean_collision', 'keyword_clean_crash', 'keyword_clean_crashed', 'keyword_clean_crush', 'keyword_clean_crushed', 'keyword_clean_curfew', 'keyword_clean_cyclone', 'keyword_clean_damage', 'keyword_clean_danger', 'keyword_clean_dead', 'keyword_clean_death', 'keyword_clean_deaths', 'keyword_clean_debris', 'keyword_clean_deluge', 'keyword_clean_deluged', 'keyword_clean_demolish', 'keyword_clean_demolished', 'keyword_clean_demolition', 'keyword_clean_derail', 'keyword_clean_derailed', 'keyword_clean_derailment', 'keyword_clean_desolate', 'keyword_clean_desolation', 'keyword_clean_destroy', 'keyword_clean_destroyed', 'keyword_clean_destruction', 'keyword_clean_detonate', 'keyword_clean_detonation', 'keyword_clean_devastated', 'keyword_clean_devastation', 'keyword_clean_disaster', 'keyword_clean_displaced', 'keyword_clean_drought', 'keyword_clean_drown', 'keyword_clean_drowned', 'keyword_clean_drowning', 'keyword_clean_dust%20storm', 'keyword_clean_earthquake', 'keyword_clean_electrocute', 'keyword_clean_electrocuted', 'keyword_clean_emergency', 'keyword_clean_emergency%20plan', 'keyword_clean_emergency%20services', 'keyword_clean_engulfed', 'keyword_clean_epicentre', 'keyword_clean_evacuate', 'keyword_clean_evacuated', 'keyword_clean_evacuation', 'keyword_clean_explode', 'keyword_clean_exploded', 'keyword_clean_explosion', 'keyword_clean_eyewitness', 'keyword_clean_famine', 'keyword_clean_fatal', 'keyword_clean_fatalities', 'keyword_clean_fatality', 'keyword_clean_fear', 'keyword_clean_fire', 'keyword_clean_fire%20truck', 'keyword_clean_first%20responders', 'keyword_clean_flames', 'keyword_clean_flattened', 'keyword_clean_flood', 'keyword_clean_flooding', 'keyword_clean_floods', 'keyword_clean_forest%20fire', 'keyword_clean_forest%20fires', 'keyword_clean_hail', 'keyword_clean_hailstorm', 'keyword_clean_harm', 'keyword_clean_hazard', 'keyword_clean_hazardous', 'keyword_clean_heat%20wave', 'keyword_clean_hellfire', 'keyword_clean_hijack', 'keyword_clean_hijacker', 'keyword_clean_hijacking', 'keyword_clean_hostage', 'keyword_clean_hostages', 'keyword_clean_hurricane', 'keyword_clean_injured', 'keyword_clean_injuries', 'keyword_clean_injury', 'keyword_clean_inundated', 'keyword_clean_inundation', 'keyword_clean_landslide', 'keyword_clean_lava', 'keyword_clean_lightning', 'keyword_clean_loud%20bang', 'keyword_clean_mass%20murder', 'keyword_clean_mass%20murderer', 'keyword_clean_massacre', 'keyword_clean_mayhem', 'keyword_clean_meltdown', 'keyword_clean_military', 'keyword_clean_missing', 'keyword_clean_mudslide', 'keyword_clean_natural%20disaster', 'keyword_clean_nuclear%20disaster', 'keyword_clean_nuclear%20reactor', 'keyword_clean_obliterate', 'keyword_clean_obliterated', 'keyword_clean_obliteration', 'keyword_clean_oil%20spill', 'keyword_clean_outbreak', 'keyword_clean_pandemonium', 'keyword_clean_panic', 'keyword_clean_panicking', 'keyword_clean_police', 'keyword_clean_quarantine', 'keyword_clean_quarantined', 'keyword_clean_radiation%20emergency', 'keyword_clean_rainstorm', 'keyword_clean_razed', 'keyword_clean_refugees', 'keyword_clean_rescue', 'keyword_clean_rescued', 'keyword_clean_rescuers', 'keyword_clean_riot', 'keyword_clean_rioting', 'keyword_clean_rubble', 'keyword_clean_ruin', 'keyword_clean_sandstorm', 'keyword_clean_screamed', 'keyword_clean_screaming', 'keyword_clean_screams', 'keyword_clean_seismic', 'keyword_clean_sinkhole', 'keyword_clean_sinking', 'keyword_clean_siren', 'keyword_clean_sirens', 'keyword_clean_smoke', 'keyword_clean_snowstorm', 'keyword_clean_storm', 'keyword_clean_stretcher', 'keyword_clean_structural%20failure', 'keyword_clean_suicide%20bomb', 'keyword_clean_suicide%20bomber', 'keyword_clean_suicide%20bombing', 'keyword_clean_sunk', 'keyword_clean_survive', 'keyword_clean_survived', 'keyword_clean_survivors', 'keyword_clean_terrorism', 'keyword_clean_terrorist', 'keyword_clean_threat', 'keyword_clean_thunder', 'keyword_clean_thunderstorm', 'keyword_clean_tornado', 'keyword_clean_tragedy', 'keyword_clean_trapped', 'keyword_clean_trauma', 'keyword_clean_traumatised', 'keyword_clean_trouble', 'keyword_clean_tsunami', 'keyword_clean_twister', 'keyword_clean_typhoon', 'keyword_clean_upheaval', 'keyword_clean_violent%20storm', 'keyword_clean_volcano', 'keyword_clean_war%20zone', 'keyword_clean_weapon', 'keyword_clean_weapons', 'keyword_clean_whirlwind', 'keyword_clean_wild%20fires', 'keyword_clean_wildfire', 'keyword_clean_windstorm', 'keyword_clean_wounded', 'keyword_clean_wounds', 'keyword_clean_wreck', 'keyword_clean_wreckage', 'keyword_clean_wrecked', 'top_domain_none', 'top_domain_t.co']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading processed train data...\")\n",
    "df = pd.read_csv(\"../data/processed/train_processed.csv\")\n",
    "print(\"Train shape:\", df.shape)\n",
    "\n",
    "df_test_raw = pd.read_csv(\"../data/raw/test.csv\")\n",
    "print(\"Test raw shape:\", df_test_raw.shape)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02785ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    0.570654\n",
      "1    0.429346\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"id\", \"target\", \"clean_text\"])\n",
    "text_col = df[\"clean_text\"]\n",
    "y = df[\"target\"]\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a76f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 6046 (80.0%)\n",
      "Val size:   1512 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, text_train, text_val, y_train, y_val = train_test_split(\n",
    "    X, text_col, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain size:\", len(X_train), f\"({len(X_train) / len(df):.1%})\")\n",
    "print(\"Val size:  \", len(X_val), f\"({len(X_val) / len(df):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e8fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = [\"clean_text\"]\n",
    "num_features = [col for col in X_train.columns if col not in text_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                max_features=8000, ngram_range=(1, 2), min_df=2, max_df=0.95, stop_words=\"english\"\n",
    "            ),\n",
    "            \"clean_text\",\n",
    "        ),\n",
    "        (\"passthrough\", \"passthrough\", num_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                max_iter=1000, class_weight=\"balanced\", random_state=42, solver=\"lbfgs\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4a0af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in text_train after fix: 0\n",
      "Empty strings in text_train: 2\n"
     ]
    }
   ],
   "source": [
    "text_train = text_train.fillna(\"\")\n",
    "text_val = text_val.fillna(\"\")\n",
    "\n",
    "text_train = text_train.astype(str)\n",
    "text_val = text_val.astype(str)\n",
    "\n",
    "print(\"NaN in text_train after fix:\", text_train.isna().sum())\n",
    "print(\"Empty strings in text_train:\", (text_train == \"\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391aeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-fold CV F1 scores: [0.79492188 0.78148148 0.80305927 0.79052133 0.77710843]\n",
      "Mean CV F1: 0.7894 ¬± 0.0093\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    pipeline, X_train.assign(clean_text=text_train), y_train, cv=cv, scoring=\"f1\"\n",
    ")\n",
    "\n",
    "print(\"\\n5-fold CV F1 scores:\", cv_scores)\n",
    "print(f\"Mean CV F1: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e5a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       863\n",
      "           1       0.78      0.81      0.79       649\n",
      "\n",
      "    accuracy                           0.82      1512\n",
      "   macro avg       0.82      0.82      0.82      1512\n",
      "weighted avg       0.82      0.82      0.82      1512\n",
      "\n",
      "Accuracy: 0.8201058201058201\n",
      "F1-score: 0.7936267071320182\n",
      "\n",
      "Confusion Matrix:\n",
      "[[717 146]\n",
      " [126 523]]\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train.assign(clean_text=text_train), y_train)\n",
    "y_pred_val = pipeline.predict(X_val.assign(clean_text=text_val))\n",
    "\n",
    "print(\"\\nValidation performance:\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
    "print(\"F1-score:\", f1_score(y_val, y_pred_val))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec507110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 most important features (by LogReg coef):\n",
      "location_encoded                    11.773482\n",
      "tfidf_3342                           2.394596\n",
      "tfidf_3854                           1.971874\n",
      "tfidf_4753                           1.856466\n",
      "keyword_clean_derailment             1.746473\n",
      "keyword_clean_oil%20spill            1.736326\n",
      "tfidf_7159                           1.727716\n",
      "keyword_clean_nuclear%20disaster     1.724155\n",
      "tfidf_5857                           1.708804\n",
      "keyword_clean_wild%20fires           1.699712\n",
      "keyword_clean_typhoon                1.691444\n",
      "keyword_clean_debris                 1.668591\n",
      "keyword_clean_suicide%20bombing      1.667518\n",
      "tfidf_6690                           1.663368\n",
      "keyword_clean_outbreak               1.653393\n",
      "keyword_clean_mass%20murder          1.584129\n",
      "tfidf_1208                           1.559466\n",
      "tfidf_1756                           1.551488\n",
      "keyword_clean_forest%20fires         1.531295\n",
      "keyword_clean_wreckage               1.494667\n",
      "dtype: float64\n",
      "\n",
      "Top 20 least important (negative coef):\n",
      "keyword_clean_demolish      -1.191107\n",
      "tfidf_2734                  -1.193916\n",
      "tfidf_1004                  -1.202044\n",
      "keyword_clean_collide       -1.211337\n",
      "tfidf_7463                  -1.213075\n",
      "keyword_clean_wrecked       -1.220867\n",
      "keyword_clean_hellfire      -1.232636\n",
      "keyword_clean_blight        -1.305605\n",
      "tfidf_6508                  -1.319638\n",
      "keyword_clean_body%20bag    -1.322008\n",
      "tfidf_7821                  -1.325540\n",
      "keyword_clean_explode       -1.354504\n",
      "keyword_clean_armageddon    -1.369380\n",
      "keyword_clean_army          -1.385257\n",
      "keyword_clean_body%20bags   -1.482146\n",
      "keyword_clean_blazing       -1.574852\n",
      "keyword_clean_aftershock    -1.623015\n",
      "tfidf_1378                  -1.781714\n",
      "tfidf_4221                  -1.845561\n",
      "tfidf_4787                  -1.981955\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tfidf_step = pipeline.named_steps[\"preprocessor\"].named_transformers_[\"tfidf\"]\n",
    "feature_names = [\n",
    "    f\"tfidf_{i}\" for i in range(tfidf_step.get_feature_names_out().shape[0])\n",
    "] + num_features\n",
    "\n",
    "coefs = pd.Series(pipeline.named_steps[\"classifier\"].coef_[0], index=feature_names).sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 most important features (by LogReg coef):\")\n",
    "print(coefs.head(20))\n",
    "\n",
    "print(\"\\nTop 20 least important (negative coef):\")\n",
    "print(coefs.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bdebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:11:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:11:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       863\n",
      "           1       0.78      0.81      0.79       649\n",
      "\n",
      "    accuracy                           0.82      1512\n",
      "   macro avg       0.82      0.82      0.82      1512\n",
      "weighted avg       0.82      0.82      0.82      1512\n",
      "\n",
      "Accuracy: 0.8201058201058201\n",
      "F1-score: 0.7936267071320182\n",
      "\n",
      "Confusion Matrix:\n",
      "[[717 146]\n",
      " [126 523]]\n",
      "üèÉ View run tfidf_logreg_pipeline at: http://localhost:5000/#/experiments/0/runs/f5276517042640ba801a498b6e1210af\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.set_experiment(\"disaster_tweets_baseline\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"tfidf_logreg_pipeline\"):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train.assign(clean_text=text_train), y_train, cv=cv, scoring=\"f1\"\n",
    "    )\n",
    "\n",
    "    mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "    mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "    mlflow.log_param(\"max_features\", 8000)\n",
    "    mlflow.log_param(\"ngram_range\", \"(1,2)\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"solver\", \"lbfgs\")\n",
    "\n",
    "    pipeline.fit(X_train.assign(clean_text=text_train), y_train)\n",
    "    y_pred_val = pipeline.predict(X_val.assign(clean_text=text_val))\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_val)\n",
    "    acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_f1\", f1)\n",
    "    mlflow.log_metric(\"val_accuracy\", acc)\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "    print(\"\\nValidation performance:\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"F1-score:\", f1)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e65f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:21:02 INFO mlflow.tracking.fluent: Experiment with name 'disaster_tweets_baseline' does not exist. Creating a new experiment.\n",
      "2026/02/19 23:21:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:21:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: {'max_features': 8000, 'ngram_range': (1, 2), 'C': 1.0, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7894184781306403\n",
      "Val F1: 0.7936267071320182\n",
      "Val Accuracy: 0.8201058201058201\n",
      "üèÉ View run tfidf_logreg_8000_1.0 at: http://localhost:5000/#/experiments/1/runs/bf73552e9ac546ed86345e8ef1fd93ae\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:21:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:21:51 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: {'max_features': 10000, 'ngram_range': (1, 2), 'C': 0.5, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7853717940630622\n",
      "Val F1: 0.787556904400607\n",
      "Val Accuracy: 0.8148148148148148\n",
      "üèÉ View run tfidf_logreg_10000_0.5 at: http://localhost:5000/#/experiments/1/runs/a9812e8f4a7c49228ccd3214189f43bd\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:22:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:22:24 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: {'max_features': 12000, 'ngram_range': (1, 3), 'C': 2.0, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "CV F1 mean: 0.7782948118355534\n",
      "Val F1: 0.7834586466165413\n",
      "Val Accuracy: 0.8095238095238095\n",
      "üèÉ View run tfidf_logreg_12000_2.0 at: http://localhost:5000/#/experiments/1/runs/3a44c88bc3a24c1ba781764b634086ae\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:22:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:22:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: {'max_features': 15000, 'ngram_range': (1, 2), 'C': 0.1, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "CV F1 mean: 0.73095235097427\n",
      "Val F1: 0.7279466271312083\n",
      "Val Accuracy: 0.7572751322751323\n",
      "üèÉ View run tfidf_logreg_15000_0.1 at: http://localhost:5000/#/experiments/1/runs/15827398ecc644e68025391ab39a2be4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:22:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:22:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: {'max_features': 8000, 'ngram_range': (1, 1), 'C': 5.0, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.787864154419019\n",
      "Val F1: 0.7945205479452054\n",
      "Val Accuracy: 0.8214285714285714\n",
      "üèÉ View run tfidf_logreg_8000_5.0 at: http://localhost:5000/#/experiments/1/runs/552ebc78e2e54a34a52870bb371e8523\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"disaster_tweets_baseline\")\n",
    "\n",
    "param_combinations = [\n",
    "    {\"max_features\": 8000, \"ngram_range\": (1, 2), \"C\": 1.0, \"solver\": \"lbfgs\", \"penalty\": \"l2\"},\n",
    "    {\"max_features\": 10000, \"ngram_range\": (1, 2), \"C\": 0.5, \"solver\": \"lbfgs\", \"penalty\": \"l2\"},\n",
    "    {\n",
    "        \"max_features\": 12000,\n",
    "        \"ngram_range\": (1, 3),\n",
    "        \"C\": 2.0,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"penalty\": \"l1\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 15000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"C\": 0.1,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"penalty\": \"l1\",\n",
    "    },\n",
    "    {\"max_features\": 8000, \"ngram_range\": (1, 1), \"C\": 5.0, \"solver\": \"lbfgs\", \"penalty\": \"l2\"},\n",
    "]\n",
    "\n",
    "for params in param_combinations:\n",
    "    with mlflow.start_run(run_name=f\"tfidf_logreg_{params['max_features']}_{params['C']}\"):\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=params[\"max_features\"],\n",
    "            ngram_range=params[\"ngram_range\"],\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            stop_words=\"english\",\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"tfidf\", tfidf, \"clean_text\"),\n",
    "                (\"passthrough\", \"passthrough\", num_features),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\n",
    "                    \"classifier\",\n",
    "                    LogisticRegression(\n",
    "                        max_iter=2000,\n",
    "                        C=params[\"C\"],\n",
    "                        solver=params[\"solver\"],\n",
    "                        penalty=params[\"penalty\"],\n",
    "                        class_weight=\"balanced\",\n",
    "                        random_state=42,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline, X_train.assign(clean_text=text_train), y_train, cv=cv, scoring=\"f1\"\n",
    "        )\n",
    "\n",
    "        mlflow.log_param(\"max_features\", params[\"max_features\"])\n",
    "        mlflow.log_param(\"ngram_range\", str(params[\"ngram_range\"]))\n",
    "        mlflow.log_param(\"C\", params[\"C\"])\n",
    "        mlflow.log_param(\"solver\", params[\"solver\"])\n",
    "        mlflow.log_param(\"penalty\", params[\"penalty\"])\n",
    "\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "\n",
    "        pipeline.fit(X_train.assign(clean_text=text_train), y_train)\n",
    "        y_pred_val = pipeline.predict(X_val.assign(clean_text=text_val))\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_val)\n",
    "        acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        mlflow.log_metric(\"val_f1\", f1)\n",
    "        mlflow.log_metric(\"val_accuracy\", acc)\n",
    "\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "        print(f\"\\nParams: {params}\")\n",
    "        print(\"CV F1 mean:\", cv_scores.mean())\n",
    "        print(\"Val F1:\", f1)\n",
    "        print(\"Val Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:29:24 INFO mlflow.tracking.fluent: Experiment with name 'disaster_tweets_baseline_v2' does not exist. Creating a new experiment.\n",
      "2026/02/19 23:29:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:29:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/10] Params: {'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 2, 'sublinear_tf': True, 'norm': 'l2', 'C': 0.5, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7860 ¬± 0.0102\n",
      "Val F1: 0.7879\n",
      "Val Accuracy: 0.8148\n",
      "üèÉ View run run_01_mf10000_C0.5_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/98022c5f62684e18aeaac4508e958664\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:29:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:29:45 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/10] Params: {'max_features': 12000, 'ngram_range': (1, 3), 'min_df': 3, 'sublinear_tf': True, 'norm': 'l2', 'C': 1.0, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "CV F1 mean: 0.7828 ¬± 0.0100\n",
      "Val F1: 0.7789\n",
      "Val Accuracy: 0.8056\n",
      "üèÉ View run run_02_mf12000_C1.0_ngram(1, 3) at: http://localhost:5000/#/experiments/2/runs/0753dd02add0418485ccbfdfdee0549f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:29:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:29:55 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/10] Params: {'max_features': 15000, 'ngram_range': (1, 2), 'min_df': 2, 'sublinear_tf': False, 'norm': 'l1', 'C': 2.0, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7785 ¬± 0.0124\n",
      "Val F1: 0.7754\n",
      "Val Accuracy: 0.8016\n",
      "üèÉ View run run_03_mf15000_C2.0_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/431127c4b8bf429bb89e14f70cec6bcc\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:29:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:30:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/10] Params: {'max_features': 8000, 'ngram_range': (1, 2), 'min_df': 5, 'sublinear_tf': True, 'norm': 'l2', 'C': 0.1, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7420 ¬± 0.0171\n",
      "Val F1: 0.7399\n",
      "Val Accuracy: 0.7698\n",
      "üèÉ View run run_04_mf8000_C0.1_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/9135451f95074435ae80f90fb8e49ade\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:30:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:30:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/10] Params: {'max_features': 10000, 'ngram_range': (1, 1), 'min_df': 2, 'sublinear_tf': True, 'norm': 'l2', 'C': 0.01, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "CV F1 mean: 0.6269 ¬± 0.0107\n",
      "Val F1: 0.6169\n",
      "Val Accuracy: 0.6230\n",
      "üèÉ View run run_05_mf10000_C0.01_ngram(1, 1) at: http://localhost:5000/#/experiments/2/runs/6f511b016b404009b10f32c437cb7248\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 23:32:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 23:32:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/10] Params: {'max_features': 12000, 'ngram_range': (1, 2), 'min_df': 3, 'sublinear_tf': True, 'norm': 'l2', 'C': 1.0, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.5}\n",
      "CV F1 mean: 0.7623 ¬± 0.0115\n",
      "Val F1: 0.7625\n",
      "Val Accuracy: 0.7890\n",
      "üèÉ View run run_06_mf12000_C1.0_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/3825bf6ffb5540a999186a0df7439662\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 00:10:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/20 00:10:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/10] Params: {'max_features': 15000, 'ngram_range': (1, 3), 'min_df': 2, 'sublinear_tf': True, 'norm': 'l2', 'C': 2.0, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.2}\n",
      "CV F1 mean: 0.7656 ¬± 0.0135\n",
      "Val F1: 0.7652\n",
      "Val Accuracy: 0.7930\n",
      "üèÉ View run run_07_mf15000_C2.0_ngram(1, 3) at: http://localhost:5000/#/experiments/2/runs/1f92fc43214447f18c0ed876ff6c950b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 00:11:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/20 00:11:55 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/10] Params: {'max_features': 10000, 'ngram_range': (1, 2), 'min_df': 3, 'sublinear_tf': False, 'norm': 'l1', 'C': 0.5, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.8}\n",
      "CV F1 mean: 0.7375 ¬± 0.0206\n",
      "Val F1: 0.7382\n",
      "Val Accuracy: 0.7646\n",
      "üèÉ View run run_08_mf10000_C0.5_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/ad4bf28d52b54557a40cf15910d6300a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 00:12:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/20 00:12:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9/10] Params: {'max_features': 20000, 'ngram_range': (1, 2), 'min_df': 2, 'sublinear_tf': True, 'norm': 'l2', 'C': 5.0, 'solver': 'lbfgs', 'penalty': 'l2'}\n",
      "CV F1 mean: 0.7858 ¬± 0.0122\n",
      "Val F1: 0.7920\n",
      "Val Accuracy: 0.8208\n",
      "üèÉ View run run_09_mf20000_C5.0_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/fe508497f5e14611a8f5a5c096d398e9\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/20 00:12:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/20 00:12:58 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10/10] Params: {'max_features': 5000, 'ngram_range': (1, 2), 'min_df': 5, 'sublinear_tf': True, 'norm': 'l2', 'C': 10.0, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "CV F1 mean: 0.7542 ¬± 0.0139\n",
      "Val F1: 0.7602\n",
      "Val Accuracy: 0.7897\n",
      "üèÉ View run run_10_mf5000_C10.0_ngram(1, 2) at: http://localhost:5000/#/experiments/2/runs/b60b0f8e5f884c73ace9292c21ad23d6\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"disaster_tweets_baseline_v2\")\n",
    "\n",
    "param_combinations = [\n",
    "    {\n",
    "        \"max_features\": 10000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 2,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 0.5,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"penalty\": \"l2\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 12000,\n",
    "        \"ngram_range\": (1, 3),\n",
    "        \"min_df\": 3,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 1.0,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"penalty\": \"l1\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 15000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 2,\n",
    "        \"sublinear_tf\": False,\n",
    "        \"norm\": \"l1\",\n",
    "        \"C\": 2.0,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"penalty\": \"l2\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 8000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 5,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 0.1,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"penalty\": \"l2\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 10000,\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"min_df\": 2,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 0.01,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"penalty\": \"l1\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 12000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 3,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 1.0,\n",
    "        \"solver\": \"saga\",\n",
    "        \"penalty\": \"elasticnet\",\n",
    "        \"l1_ratio\": 0.5,\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 15000,\n",
    "        \"ngram_range\": (1, 3),\n",
    "        \"min_df\": 2,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 2.0,\n",
    "        \"solver\": \"saga\",\n",
    "        \"penalty\": \"elasticnet\",\n",
    "        \"l1_ratio\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 10000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 3,\n",
    "        \"sublinear_tf\": False,\n",
    "        \"norm\": \"l1\",\n",
    "        \"C\": 0.5,\n",
    "        \"solver\": \"saga\",\n",
    "        \"penalty\": \"elasticnet\",\n",
    "        \"l1_ratio\": 0.8,\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 20000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 2,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 5.0,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"penalty\": \"l2\",\n",
    "    },\n",
    "    {\n",
    "        \"max_features\": 5000,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 5,\n",
    "        \"sublinear_tf\": True,\n",
    "        \"norm\": \"l2\",\n",
    "        \"C\": 10.0,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"penalty\": \"l1\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for idx, params in enumerate(param_combinations, 1):\n",
    "    run_name = (\n",
    "        f\"run_{idx:02d}_mf{params['max_features']}_C{params['C']}_ngram{params['ngram_range']}\"\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=params[\"max_features\"],\n",
    "            ngram_range=params[\"ngram_range\"],\n",
    "            min_df=params.get(\"min_df\", 2),\n",
    "            max_df=0.95,\n",
    "            stop_words=\"english\",\n",
    "            sublinear_tf=params.get(\"sublinear_tf\", False),\n",
    "            norm=params.get(\"norm\", \"l2\"),\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"tfidf\", tfidf, \"clean_text\"),\n",
    "                (\"passthrough\", \"passthrough\", num_features),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "        )\n",
    "\n",
    "        classifier_params = {\n",
    "            \"max_iter\": 2000,\n",
    "            \"C\": params[\"C\"],\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "\n",
    "        if \"solver\" in params:\n",
    "            classifier_params[\"solver\"] = params[\"solver\"]\n",
    "        if \"penalty\" in params:\n",
    "            classifier_params[\"penalty\"] = params[\"penalty\"]\n",
    "        if \"l1_ratio\" in params:\n",
    "            classifier_params[\"l1_ratio\"] = params[\"l1_ratio\"]\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"classifier\", LogisticRegression(**classifier_params)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline, X_train.assign(clean_text=text_train), y_train, cv=cv, scoring=\"f1\", n_jobs=-1\n",
    "        )\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
    "\n",
    "        pipeline.fit(X_train.assign(clean_text=text_train), y_train)\n",
    "        y_pred_val = pipeline.predict(X_val.assign(clean_text=text_val))\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_val)\n",
    "        acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        mlflow.log_metric(\"val_f1\", f1)\n",
    "        mlflow.log_metric(\"val_accuracy\", acc)\n",
    "\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "        print(f\"\\n[{idx}/{len(param_combinations)}] Params: {params}\")\n",
    "        print(f\"CV F1 mean: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "        print(f\"Val F1: {f1:.4f}\")\n",
    "        print(f\"Val Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disaster_tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
